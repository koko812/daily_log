# Token-Free & Ensemble Decoding â€• ã‚»ãƒƒã‚·ãƒ§ãƒ³ç·æ‹¬

## 1. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æµã‚Œã¨ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯
1. **Diffusion-LM è©±é¡Œ** â†’ Mercury ãªã© â€œDiffusion Ã— LMâ€ ã®æ–°æ½®æµ  
2. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ»åˆæµç³»**  
   - CharED, Token-level Ensembling, Lattice Beam, Lookahead/Look-back Beam  
3. **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»å°å‹ãƒ¢ãƒ‡ãƒ«æ¢ç´¢**  
   - Stable Code 3B, Qwen2.5-Coder 3B, 1B/3B ã‚¯ãƒ©ã‚¹æ¯”è¼ƒ  
4. **ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å†è€ƒ**  
   - BPE vs UnigramLMã€token-less (ByT5, Canine) ã¸  
5. **æœ€æ–° token-free ãƒ¢ãƒ‡ãƒ«**  
   - SpaceByte, MambaByte, BLTã€Exact Byte-Level Probabilities  
6. **æ¢ç´¢ã‚³ã‚¹ãƒˆãƒ»ãƒ¡ãƒ¢ãƒªè¨ˆæ¸¬è­°è«–**  
   - ãƒãƒ¼ãƒ‰å±•é–‹æ•°ã¨ GPU ãƒ¡ãƒ¢ãƒªã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ–¹æ³•

## 2. æ·±æ˜ã‚ŠãŒé€²ã‚“ã ãƒˆãƒ”ãƒƒã‚¯
| ãƒˆãƒ”ãƒƒã‚¯ | æ·±æ˜ã‚Šå†…å®¹ |
|---------|-----------|
| **CharED** | æ–‡å­—å˜ä½ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®å¯èƒ½æ€§ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®‰å®šæ€§ãƒ»å¤šæ§˜æ€§é™ç•Œ |
| **Token-level Ensembling** | èªå½™ã®ç•°ãªã‚‹ LLM åŒå£«ã®åŒæœŸï¼åˆæµãƒ­ã‚¸ãƒƒã‚¯ |
| **Lattice Decoding** | åˆæµã¨å¤šæ§˜æ€§ãƒ»éè‹±èªç”Ÿæˆã®èª²é¡Œãƒ»ãƒãƒ¼ãƒ‰ã‚³ã‚¹ãƒˆ |
| **Lookahead / Look-back Beam** | æ·±ã•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ vs å±¥æ­´ KL åˆ¶å¾¡ã®æ¯”è¼ƒ |
| **Token-free Models** | Byte/Char ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡ãƒ»æ§‹æ–‡ç†è§£ã€æœ€æ–° 2024â€“25 è«–æ–‡ |

## 3. è«–æ–‡ä¸€è¦§ï¼ˆæ¼ã‚Œãªãåˆ—æŒ™ï¼‰
| ã‚¿ã‚¤ãƒˆãƒ« | ä¼šè­°ãƒ»å¹´ | 1â€“2 è¡Œè¦ç´„ |
|----------|---------|------------|
| **Mercury: Ultra-Fast Language Models Based on Diffusion** | ICLR 2024 | ç”Ÿæˆé€Ÿåº¦ã‚’æ‹¡å¼µå‹ diffusion ã§ 10Ã— é«˜é€ŸåŒ–ã—ãŸåˆæœŸææ¡ˆ |
| **RePPL / LLM-Check** | arXiv 2023 | ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼Œè¨€èªãƒ¢ãƒ‡ãƒ«è‡ªå·±å†è©•ä¾¡ |
| **Character-wise Ensemble Decoding (CharED)** | arXiv 2024 | ç•°ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ LLM ã‚’æ–‡å­—ç¢ºç‡ã§çµ±åˆï¼ŒHumanEval/GSM8K å‘ä¸Š |
| **Token-level Ensembling of Models with Different Vocabularies** | arXiv 2025 | æ–‡å­—ä¸€è‡´ã§ç¢ºç‡åˆæµã™ã‚‹è»½é‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ŒBLEU æ”¹å–„ |
| **On the Depth between Beam Search and Exhaustive Search for Text Generation** | arXiv 2023 | Lookahead æ·±ã• 2â€“3 ã§ BLEU +1ã€œ2ï¼ŒBeamâ‡„å…¨æ¢ç´¢ã®ä¸­åº¸ |
| **Lookbehind Heuristic Beam Search** | arXiv 2023 | LBS ã‚’ 1 ã‚¹ãƒ†ãƒƒãƒ—è¿‘ä¼¼ã— Beam ã‚³ã‚¹ãƒˆã§ç²¾åº¦ç¶­æŒ |
| **Look-back Decoding for Open-Ended Text Generation** | EMNLP 2023 | Past KL ã§ãƒˆãƒ”ãƒƒã‚¯é€¸è„±ã‚’æŠ‘åˆ¶ï¼Œã‚¹ãƒˆãƒ¼ãƒªãƒ¼ç”Ÿæˆå‘ä¸Š |
| **NeuroLogic Decoding: (Un)supervisedâ€¦** | ACL 2020 | è«–ç†åˆ¶ç´„ã‚’æº€ãŸã™ãƒ“ãƒ¼ãƒ æ¢ç´¢ã§å¿…é ˆèªå¥ãƒ»èªé †ã‚’ä¿è¨¼ |
| **NeuroLogic A\*esque Decodingâ€¦** | NAACL 2021 | ä¸Šè¨˜ã« A\* çš„ lookahead ã‚’åŠ ãˆï¼Œæµæš¢æ€§ã¾ã§æœ€é©åŒ– |
| **Massive-scale Decoding for Text Generation using Lattices** | NAACL 2022 | n-gram åˆæµãƒ©ãƒ†ã‚£ã‚¹ã§å¤šæ§˜æ€§ã¨æ–‡æ³•æ€§ã‚’ä¸¡ç«‹ï¼Œãƒãƒ¼ãƒ‰åœ§ç¸® |
| **Pushing the Limits of Beam Search Decoding for Transducer-based Models** | arXiv 2025 | ASR ç”¨åˆæµã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼Œå±•é–‹â†’mergeâ†’prune ã®3æ®µéš |
| **Lattice Generation in Attention-Based Speech Recognition Models** | Interspeech 2019 | TCN-ASR ã§çŠ¶æ…‹å…±æœ‰ãƒãƒ¼ãƒ‰ã‚’ãƒãƒ¼ã‚¸ã—æ¨è«–åŠ¹ç‡åŒ– |
| **Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles** | ICLR 2025 | è¿½åŠ å­¦ç¿’ç„¡ã—ã§ãƒã‚¤ãƒˆç¢ºç‡ã‚’å³å¯†å¾©å…ƒï¼ŒFIM +18 %, Ensemble +3.7 % |
| **SpaceByte: Towards Deleting Tokenization from LLM** | NeurIPS 2024 | ç©ºç™½å¢ƒç•Œã«éšå±¤ãƒ–ãƒ­ãƒƒã‚¯ï¼Œbyte-level ã§ subword ä¸¦æ€§èƒ½ |
| **MambaByte: Token-free Selective State Space Model** | arXiv 2024 | SSM + speculative decodingï¼Œé•·ç³»åˆ—åŠ¹ç‡ã¨2.6Ã—æ¨è«–é€Ÿåº¦ |
| **Byte Latent Transformer (BLT)** | Meta Tech Report 2024 | Dynamic patching ã«ã‚ˆã‚Š byte-level ã§ LLaMA3 ç­‰ä¾¡æ€§èƒ½ |
| **Hierarchical Autoregressive Transformers** | ICLR 2025 | Charâ†’Word ã®äºŒå±¤ã§ token-free ã¨ subword ã‚’èåˆ |
| **ByT5: Towards a Token-Free Futureâ€¦** | TACL 2022 | Byte-to-Byte T5ï¼Œå°ãƒ¢ãƒ‡ãƒ«å¼·ã„ãŒ large ã§ subword åŠ£å¾Œ |
| **Canine: Pre-training an Efficient Tokenization-Free Encoder** | ACL 2021 | Char ç›´æ¥å­¦ç¿’ + Downsamplingï¼Œãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ä¸è¦ |
| **Charformer: Fast Character Transformers via Gradient-based Subword Tokenization** | ICLR 2022 | Soft span é¸æŠã§å‹•çš„ subword å­¦ç¿’ï¼Œé€Ÿåº¦å‘ä¸Š |
| **Tiktoken** | OpenAI 2023 (tech note) | BPE æ”¹è‰¯ãƒ»JSON/ã‚³ãƒ¼ãƒ‰æœ€é©åŒ–ï¼ŒGPT-4 ç³»æ¨™æº– |
| **Papers on Stable Code / Qwen / Granite etc.** | 2023â€“24 å¤šæ•° | 3B-class code LLM ã®æ¯”è¼ƒç ”ç©¶ (çœç•¥ä¸å¯ã¨ã—ã¦è¨€åŠ) |

## 4. ã‚¢ãƒ—ãƒªã‚¢ã‚¤ãƒ‡ã‚¢ä¸€è¦§
| ğŸ› ï¸ ã‚¢ã‚¤ãƒ‡ã‚¢ | ç›®çš„ | æ©Ÿèƒ½æ¦‚è¦ |
|--------------|------|----------|
| CharED + Syntax Validator | æ–‡å­—åˆæµå¾Œã®æ§‹æ–‡ç ´ç¶»æ¤œå‡º | Python AST ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ç›´å¾Œã«æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ |
| ãƒãƒ¼ãƒ‰æ•°-ãƒ¡ãƒ¢ãƒª Profiler | ãƒ“ãƒ¼ãƒ æ¢ç´¢ã®ãƒ¡ãƒ¢ãƒªå¯è¦–åŒ– | torch.cuda.memory + logging, Nsight trace |
| Byte-to-Subword Converter | Byte-level LLM â†” Tokenized LLM ã‚’åˆ‡æ›¿ | Exact Byteâ€Level ç†è«–ã‚’å®Ÿè£…ã—ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤å¤‰æ› |

## 5. ãƒ¦ãƒ¼ã‚¶ãƒ¼é–¢å¿ƒãƒˆãƒƒãƒ—5è«–æ–‡ï¼ˆè©³ç´°è¦ç´„ï¼‰

### 1. **Token-level Ensembling of Models with Different Vocabularies** (Wicks et al., arXiv 2025)  
èªå½™ãŒç•°ãªã‚‹ LLM åŒå£«ã‚’ã€ãƒ‡ãƒˆãƒ¼ã‚¯ãƒ³å¾Œã®æ–‡å­—åˆ—ä¸€è‡´ã§ç¬æ™‚ã«åŒæœŸã—ç¢ºç‡ã‚’åˆæµã™ã‚‹â€œAgreement-Based Ensemblingâ€ã€‚è¿½åŠ å­¦ç¿’ãªã—ã« MT BLEU ã‚’å‘ä¸Šã•ã›ã€ç•°èªå½™ãƒ¢ãƒ‡ãƒ«èåˆã®ãƒãƒ¼ãƒ‰ãƒ«ã‚’å¤§ããä¸‹ã’ãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèªå½™éä¾å­˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«å¼·ã„é–¢å¿ƒã‚’ç¤ºã—ãŸã€‚

### 2. **Character-wise Ensemble Decoding (CharED)** (arXiv 2024)  
ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã«ç¸›ã‚‰ã‚Œãšæ–‡å­—ç¢ºç‡ã‚’æ¯”è¼ƒã—ã¦çµ±åˆã™ã‚‹é©æ–°çš„ãƒ‡ã‚³ãƒ¼ãƒ€ã€‚HumanEvalãƒ»GSM8K ã§ 13B+13B ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç¶­æŒã‚„å¤šãƒ¢ãƒ‡ãƒ«ç›¸è£œã®è­°è«–ãŒæ·±ã¾ã£ãŸã€‚

### 3. **Massive-scale Decoding for Text Generation using Lattices** (Xu et al., NAACL 2022)  
ãƒ“ãƒ¼ãƒ æ¢ç´¢ã‚’ Best-firstï¼‹ãƒ©ãƒ†ã‚£ã‚¹åˆæµã«ç½®ãæ›ãˆã€æ•°åƒå€™è£œã‚’åœ§ç¸®ä¿æŒã€‚å¤šæ§˜æ€§ï¼å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ”¹å–„ã—ã€åˆæµã¨å¤šè¨€èªç”Ÿæˆã®èª²é¡Œã«ã¤ã„ã¦è­°è«–ãŒé›†ä¸­ã€‚

### 4. **Exact Byte-Level Probabilitiesâ€¦** (Phan et al., ICLR 2025)  
Tokenized LLM ã‚’è¿½åŠ å­¦ç¿’ãªã—ã§ byte-level ã¨åŒç­‰ç¢ºç‡ã«å¤‰æ›ã™ã‚‹ç†è«–çš„â¼¿æ³•ã€‚FIM +18 %ã€Ensemble +3.7 % ã‚’é”æˆã—ã€ã€Œæ€§èƒ½åŠ£åŒ–ãªã token-free åŒ–ã€ã®å¯å¦ã«å¼·ã„é–¢å¿ƒãŒå¯„ã›ã‚‰ã‚ŒãŸã€‚

### 5. **On the Depth between Beam Search and Exhaustive Search for Text Generation** (Jinnai et al., arXiv 2023)  
Lookahead æ·±åº¦ã‚’å¯å¤‰ã«ã—ã€Beam 0â†”å…¨æ¢ç´¢âˆã®ä¸­é–“ã§æœ€è‰¯ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹ã€‚æ·±ã•2â€“3ã§ BLEU æ”¹å–„ãŒç¤ºã•ã‚Œã€æ·±ã•åˆ¶å¾¡ã¨æ¢ç´¢ã‚³ã‚¹ãƒˆã®è­°è«–ãŒæ´»ç™ºåŒ–ã€‚

