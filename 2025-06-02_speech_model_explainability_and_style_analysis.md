## ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦

ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã¯ã€éŸ³å£°ã¨è¨€èªã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã€Œè§£é‡ˆå¯èƒ½æ€§ã€ã€Œã‚¹ã‚¿ã‚¤ãƒ«åˆ†æã€ã€ŒéŸ³ç´ å‡¦ç†ã€ãªã©ã‚’è»¸ã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæŠ€è¡“ãƒ»è«–æ–‡ãƒ»è­°è«–ã‚’å¹…åºƒãå±•é–‹ã—ãŸï¼š

### ğŸ”¹ è©±é¡Œã®æµã‚Œãƒ»æŠ€è¡“ã®ç„¦ç‚¹
- ChatGPTã¨ã®å”èª¿ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¯åˆ¶é™ã®å°‘ãªã„ GPT-4-turbo ãŒæœ‰æœ›ã€‚
- CLAPï¼ˆContrastive Language-Audio Pretrainingï¼‰ãƒ¢ãƒ‡ãƒ«ã®æ€§è³ªã¨å¿œç”¨ã«ã¤ã„ã¦æ•´ç†ã€‚
- CLAPCap, AudioLDM ãªã©éŸ³å£°ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ã¨ãã®äººå£°å¯¾å¿œã€‚
- éŸ³å£°ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã®æœ€æ–°ç ”ç©¶å‹•å‘ï¼ˆAudioCaption, Qwen-Audio ãªã©ï¼‰ã€‚
- Whisper ã® forced alignment ç‰¹æ€§ã¨éŸ³ç´ å˜ä½èªè­˜ã®é™ç•Œã€‚
- ECAPA ã®åŸ‹ã‚è¾¼ã¿ãŒè©±è€…ã‚’ã†ã¾ãåˆ†é›¢ã§ãã‚‹ç†ç”±ã¨ãã®è§£æå¯èƒ½æ€§ã€‚
- ç™ºè©±ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚¢ã‚¯ã‚»ãƒ³ãƒˆãƒ»éŸ³éŸ¿çš„å¤‰å‹•ï¼‰åˆ†æã®ç ”ç©¶å‹•å‘ã€‚
- L2-Arctic ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ã£ãŸç™ºè©±ã‚¹ã‚¿ã‚¤ãƒ«ç ”ç©¶ã®ã‚µãƒ¼ãƒ™ã‚¤ã¨è«–æ–‡ç´¹ä»‹ã€‚
- Accent conversion ã«ãŠã‘ã‚‹ articulatory representationï¼ˆTVs, PPGs, HuBERT embeddingsï¼‰ã®æ„å‘³ã¨å‡ºå…¸ã€‚
- Grad-CAM / LRP ã‚’ç”¨ã„ãŸéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ï¼ˆWav2Vec, Whisperãªã©ï¼‰ã®å¯è¦–åŒ–æ‰‹æ³•ã®é€²å±•ã€‚
- Transformerãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§ã«é–¢ã™ã‚‹2ã¤ã®é‡è¦è«–æ–‡ã®è§£èª¬ã€‚

---

## è­°è«–ãŒè†¨ã‚‰ã‚“ã è©±é¡Œ

- **èª¿éŸ³å¤‰æ•°ï¼ˆTVsï¼‰ã¨éŸ³éŸ¿ç‰¹å¾´é‡ï¼ˆPPGï¼‰ã«ã‚ˆã‚‹ç™ºè©±ã‚¹ã‚¿ã‚¤ãƒ«ã®å¤‰æ›**
  - éŸ³ç´ å˜ä½åˆ¶å¾¡ã¨L2è©±è€…ã¸ã®é©ç”¨å¯èƒ½æ€§
  - TVsã®å‡ºå…¸ï¼ˆspeech inversionã«åŸºã¥ã6æ¬¡å…ƒè¡¨ç¾ï¼‰ã®è§£é‡ˆ
  - PPGsã®ä¸‰éŸ³ç´ è¡¨ç¾ï¼ˆtri-phoneï¼‰ã®æ„å‘³ã¨ä¸€èˆ¬æ€§

- **éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã¸ã®å¯è¦–åŒ–æ‰‹æ³•ã®å¿œç”¨**
  - Whisperã‚„Wav2Vec 2.0ãªã©ã«å¯¾ã™ã‚‹Grad-CAMã‚„LRPã®å¿œç”¨äº‹ä¾‹
  - å¯è¦–åŒ–çµæœã®ä¿¡é ¼æ€§ãƒ»å®Ÿç”¨æ€§ãƒ»ç²¾åº¦ã«é–¢ã™ã‚‹è­°è«–

- **ViTï¼ˆVision Transformerï¼‰ç³»åˆ—ã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹è§£é‡ˆå¯èƒ½æ€§**
  - attentionã«ä¾å­˜ã—ãªã„ä¸­é–“å±¤ã‹ã‚‰ã®é–¢é€£æ€§ä¼æ’­
  - è§£é‡ˆæ€§ã®è©•ä¾¡æŒ‡æ¨™ã®æ•´ç†ï¼ˆå¿ å®Ÿæ€§ã€ä¸€è²«æ€§ã€é ‘å¥æ€§ãªã©ï¼‰

---

## ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã«å‡ºã¦ããŸè«–æ–‡ä¸€è¦§

| è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ« | ä¼šè­°å | å¹´ |
|--------------|--------|----|
| Contrastive Language-Audio Pretraining (CLAP) | - | 2023 |
| AudioCaption: Listen and Tell | ACL | 2021 |
| CLAPCap: CLAP-powered Audio Captioning | - | 2023 |
| AudioLDM: Text-to-Audio Generation | ICML | 2023 |
| Qwen2.5-Omni Technical Report | - | 2024 |
| Analyzing the Impact of Accent on English Speech | Interspeech | 2022 |
| Accent Conversion with Articulatory Representations | Interspeech | 2023 |
| Layer-wise Analysis of a Self-supervised Speech Representation Model | ASRU | 2021 |
| Visualizing Automatic Speech Recognition -- Means for a Better Understanding? | arXiv | 2022 |
| Explainability of Speech Recognition Transformers via Gradient-based Attention Visualization | - | 2023? |
| AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers | - | 2022 |
| Transformer Interpretability Beyond Attention Visualization | CVPR | 2021 |
| Explainability of Vision Transformers: A Comprehensive Review and New Perspectives | arXiv / TMLRï¼ˆæŸ»èª­ä¸­ï¼‰ | 2023 |

---


